# 📘 AI 논문 리뷰 포트폴리오

---

## ✏️ Word2Vec (2013, Mikolov)
📌 **핵심 개념**  
- 단어를 벡터 공간에 임베딩하여 의미적 유사성을 수치로 표현  

📌 **문제 정의**  
- One-hot 벡터는 단어 간 의미 관계를 반영하지 못함  

📌 **제안 방법**  
- Skip-gram, CBOW 모델로 주변 단어 맥락 학습  

📌 **결과**  
- 유사 단어 벡터 근접  
- `"king - man + woman = queen"` 같은 벡터 연산 가능  

📌 **의의**  
- 이후 NLP 임베딩 연구 및 딥러닝 발전의 기초  

---

## ✏️ Seq2Seq (2014, Sutskever)
📌 **핵심 개념**  
- Encoder-Decoder 구조로 입력 시퀀스를 다른 시퀀스로 변환  

📌 **문제 정의**  
- 전통 번역 모델은 긴 문맥과 단어 순서 학습에 한계  

📌 **제안 방법**  
- LSTM Encoder가 입력을 요약 → Decoder가 출력 시퀀스 생성  

📌 **결과**  
- 기계 번역 등 자연어 생성 성능 향상  

📌 **의의**  
- Attention/Transformer 탄생의 기반  

---

## 📖 Attention Is All You Need (2017, Vaswani)
📌 **핵심 개념**  
- Transformer 제안, RNN/CNN을 대체  
- Self-Attention으로 문맥 처리  

📌 **문제 정의**  
- RNN: 긴 문맥 처리 한계, 병렬화 어려움  
- CNN: 국소적 특징엔 강하나 문맥 전체 파악은 약함  

📌 **제안 방법**  
- Encoder-Decoder 구조 + Multi-head Self Attention  
- Positional Encoding으로 순서 정보 보강  

📌 **결과**  
- 번역 과제에서 SOTA 달성  
- 이후 GPT·BERT 등 모든 LLM의 토대가 됨  

📌 **한계 / 의의**  
- 당시 연산 자원 부족 → 대규모 학습 불가  
- 하지만 현대 LLM 혁신의 뼈대  

---

## 📖 BERT (2018, Devlin)
📌 **핵심 개념**  
- Bidirectional Encoder Representations로 문맥 이해 강화  

📌 **문제 정의**  
- 기존 LM은 좌→우, 우→좌 단방향만 가능  

📌 **제안 방법**  
- Masked LM + Next Sentence Prediction  

📌 **결과**  
- GLUE 등 다수 NLP 벤치마크에서 최고 성능  

📌 **의의**  
- 파인튜닝 기반 NLP 혁신 시작  

---

## 📖 GPT-3 (2020, Brown)
📌 **핵심 개념**  
- 초대규모 Transformer LM (175B)  
- In-Context Learning 능력  

📌 **문제 정의**  
- 소규모 모델은 Zero/Few-shot 학습 한계  

📌 **제안 방법**  
- 거대한 LM + Prompt 기반 Few-shot  

📌 **결과**  
- 다양한 과제에서 범용적 성능 발휘  

📌 **의의**  
- ChatGPT와 LLM 서비스 시대 개막  

---

## 📘 AlexNet (2012, Krizhevsky)
📌 **핵심 개념**  
- 대규모 CNN으로 이미지 분류 성능 혁신  

📌 **문제 정의**  
- 기존 비전 모델은 복잡 이미지 처리에 한계  

📌 **제안 방법**  
- ReLU, Dropout, GPU 병렬 학습  

📌 **결과**  
- ImageNet 대회 압도적 우승  

📌 **의의**  
- 딥러닝 컴퓨터비전 붐의 시작  

---

## 📘 ResNet (2015, He)
📌 **핵심 개념**  
- Residual Connection으로 초깊은 네트워크 학습 가능  

📌 **문제 정의**  
- 네트워크가 깊어질수록 기울기 소실 발생  

📌 **제안 방법**  
- Skip Connection(잔차 연결) 도입  

📌 **결과**  
- ImageNet 우승, 딥러닝 CV 성능 향상  

📌 **의의**  
- 현대 비전모델의 기본 구조  

---

## 📘 CLIP (2021, Radford)
📌 **핵심 개념**  
- 텍스트-이미지 대비학습으로 제로샷 분류 가능  

📌 **문제 정의**  
- 특정 데이터셋에 한정된 비전 모델 한계  

📌 **제안 방법**  
- 대규모 텍스트-이미지 쌍 학습  

📌 **결과**  
- 오픈도메인 제로샷 이미지 분류/검색  

📌 **의의**  
- 멀티모달 AI의 대표적 전환점  

---

## 📘 RAG (2020, Lewis)
📌 **핵심 개념**  
- Retrieval-Augmented Generation  

📌 **문제 정의**  
- LLM 환각(hallucination), 최신성 부족  

📌 **제안 방법**  
- 외부 검색 결과를 LLM 입력으로 주입  

📌 **결과**  
- QA/지식탐색 성능 향상  

📌 **의의**  
- 검색-생성 파이프라인의 표준  

---

## 📘 GraphRAG (2024)
📌 **핵심 개념**  
- 지식 그래프 기반 RAG  

📌 **문제 정의**  
- 긴 맥락·대규모 문서에서 단순 검색 한계  

📌 **제안 방법**  
- 문서를 그래프로 변환 → 요약·검색 결합  

📌 **결과**  
- 복잡 질의 처리 성능 향상  

📌 **의의**  
- 최신 RAG 발전 방향  

---

# 📑 추가 면접 질문 & 답변

**Q. Dropout은 어떤 원리로 과적합을 줄이나요?**  
✅ 학습 시 무작위로 일부 뉴런을 끄는 방식으로, 네트워크가 특정 특징에 과적합하지 않도록 하고 앙상블 효과를 냅니다.  

**Q. Batch Normalization이 학습을 안정화하는 이유는?**  
✅ 입력 분포를 정규화하여 기울기 폭주/소실을 줄이고, 더 높은 학습률 사용을 가능하게 해 학습 속도와 성능을 개선합니다.  

**Q. GPT-3의 Few-shot Learning은 어떻게 가능한가요?**  
✅ 초대규모 파라미터 덕분에 프롬프트에 포함된 예시(few-shot)를 내부 패턴으로 일반화할 수 있어, 별도 학습 없이도 다양한 태스크 수행이 가능합니다.  

**Q. BERT의 Masked LM과 GPT의 Auto-regressive LM 차이는?**  
✅ BERT는 토큰을 마스킹하고 양방향 문맥을 학습해 NLU에 강점, GPT는 이전 단어만 보고 다음 단어를 예측하는 단방향 구조라 NLG에 강점이 있습니다.  

**Q. BLIP-2가 멀티모달 연결 비용을 어떻게 줄였는가?**  
✅ 거대한 이미지 인코더와 LLM 사이에 Q-Former라는 가벼운 브릿지를 넣어, 전체 모델을 학습하지 않고도 멀티모달 연결이 가능합니다.  

**Q. LLaVA-OneVision 같은 최신 VLM이 기업에서 어떤 문제 해결에 적합한가?**  
✅ 단일 모델로 이미지, 멀티이미지, 비디오까지 처리 가능해, 제품 검수, 문서 분석, CCTV 분석 등 다양한 산업 현장 자동화에 적합합니다.  
